{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87a2355-a6f1-4f92-8f8c-3781b4416ece",
   "metadata": {},
   "source": [
    "# pistachio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ac4c5-d982-4d2c-97db-56cb0fa4932c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e3fa01-5594-4ec7-9904-05ec659b1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arff to parquet\n",
    "\n",
    "from scipy.io import arff \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "arff_filepath = './data/Pistachio_Dataset/Pistachio_16_Features_Dataset/Pistachio_16_Features_Dataset.arff'\n",
    "parquet_path = './data/pistachio_16.snappy.pqt'\n",
    "\n",
    "def arff_to_parquet(input_arff: str, output_parquet: str):\n",
    "    \"\"\"convert arff file to parquet\"\"\"\n",
    "    if not os.path.exists(input_arff):\n",
    "        raise ValueError(f\"input file '{input_arff}' does not exist\")\n",
    "    data, meta = arff.loadarff(input_arff)\n",
    "    print(\"arff metadata\")\n",
    "    print(meta)\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Class'] = df['Class'].astype(str)\n",
    "    df.to_parquet(output_parquet)\n",
    "##################\n",
    "\n",
    "if not os.path.exists(parquet_path):\n",
    "    print(\"converting arff to parquet\")\n",
    "    arff_to_parquet(arff_filepath, parquet_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7bba72-4c03-424e-8c3e-b31ddf0b5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Pistachio_16_Features_Dataset\n",
    "# \tAREA's type is numeric\n",
    "# \tPERIMETER's type is numeric\n",
    "# \tMAJOR_AXIS's type is numeric\n",
    "# \tMINOR_AXIS's type is numeric\n",
    "# \tECCENTRICITY's type is numeric\n",
    "# \tEQDIASQ's type is numeric\n",
    "# \tSOLIDITY's type is numeric\n",
    "# \tCONVEX_AREA's type is numeric\n",
    "# \tEXTENT's type is numeric\n",
    "# \tASPECT_RATIO's type is numeric\n",
    "# \tROUNDNESS's type is numeric\n",
    "# \tCOMPACTNESS's type is numeric\n",
    "# \tSHAPEFACTOR_1's type is numeric\n",
    "# \tSHAPEFACTOR_2's type is numeric\n",
    "# \tSHAPEFACTOR_3's type is numeric\n",
    "# \tSHAPEFACTOR_4's type is numeric\n",
    "# \tClass's type is nominal, range is ('Kirmizi_Pistachio', 'Siit_Pistachio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a718dd2-d43d-439f-aa38-97852dd71910",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "load data from parquet, stratify split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de70962-57cc-4309-9e43-521bd0b0076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(\n",
    "        input_parquet: str, \n",
    "        train_filename: str,\n",
    "        test_filename: str,\n",
    "        label_column: str,\n",
    "        test_fraction: float=0.2,\n",
    "        seed: int=42):\n",
    "    \"\"\"stratify sample the data\"\"\"\n",
    "    # set seed\n",
    "    # np.random.seed(seed)\n",
    "    in_df = pd.read_parquet(input_parquet)\n",
    "    y = in_df.pop(label_column)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        in_df, \n",
    "        y, \n",
    "        random_state=seed, \n",
    "        stratify=y, \n",
    "        test_size=test_fraction)\n",
    "    # reattach labels\n",
    "    x_train[label_column] = y_train\n",
    "    x_test[label_column] = y_test\n",
    "    print(f'x_train shape = {x_train.shape}')\n",
    "    print(f'y_train shape = {y_train.shape}')\n",
    "    print(f'x_test shape = {x_test.shape}')\n",
    "    print(f'y_test shape = {y_test.shape}')\n",
    "    # write data\n",
    "    x_train.to_parquet(train_filename)\n",
    "    x_test.to_parquet(test_filename)\n",
    "##############################\n",
    "\n",
    "train_path = './data/pistachio_train.pqt'\n",
    "test_path = './data/pistachio_test.pqt'\n",
    "split_seed = 41\n",
    "label_column = 'Class'\n",
    "test_fraction = 0.2\n",
    "input_data_schema_path = \"./data/pistachio_schema.json\"\n",
    "\n",
    "if not (os.path.exists(train_path) and os.path.exists(test_path)):\n",
    "    split_data(\n",
    "        parquet_path,\n",
    "        train_path,\n",
    "        test_path,\n",
    "        label_column=label_column,\n",
    "        test_fraction=test_fraction,\n",
    "        seed=split_seed)\n",
    "    print('split train and test data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546087de-0d98-496e-8917-8d071b952e88",
   "metadata": {},
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4191a32f-f3ed-4785-b8eb-948de58754dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandera[io]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebb5ac0-9e00-4855-8cdb-6c6b161c1d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>ROUNDNESS</th>\n",
       "      <th>COMPACTNESS</th>\n",
       "      <th>SHAPEFACTOR_1</th>\n",
       "      <th>SHAPEFACTOR_2</th>\n",
       "      <th>SHAPEFACTOR_3</th>\n",
       "      <th>SHAPEFACTOR_4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718.000000</td>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79990.176368</td>\n",
       "      <td>1423.800903</td>\n",
       "      <td>446.184575</td>\n",
       "      <td>238.404956</td>\n",
       "      <td>0.840033</td>\n",
       "      <td>318.003064</td>\n",
       "      <td>0.940279</td>\n",
       "      <td>85048.962165</td>\n",
       "      <td>0.715327</td>\n",
       "      <td>1.897053</td>\n",
       "      <td>0.571019</td>\n",
       "      <td>0.713397</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.510931</td>\n",
       "      <td>0.955492</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13075.738130</td>\n",
       "      <td>375.345641</td>\n",
       "      <td>32.531725</td>\n",
       "      <td>30.372990</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>26.853806</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>13180.036678</td>\n",
       "      <td>0.053204</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.212615</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.050951</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29808.000000</td>\n",
       "      <td>858.363000</td>\n",
       "      <td>320.344500</td>\n",
       "      <td>133.509600</td>\n",
       "      <td>0.504900</td>\n",
       "      <td>194.814600</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>37935.000000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>1.158500</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>0.620400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>71859.500000</td>\n",
       "      <td>1169.588750</td>\n",
       "      <td>426.337050</td>\n",
       "      <td>217.925450</td>\n",
       "      <td>0.817225</td>\n",
       "      <td>302.480300</td>\n",
       "      <td>0.920025</td>\n",
       "      <td>76334.000000</td>\n",
       "      <td>0.685225</td>\n",
       "      <td>1.735225</td>\n",
       "      <td>0.375375</td>\n",
       "      <td>0.682225</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.465425</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79997.500000</td>\n",
       "      <td>1261.599000</td>\n",
       "      <td>448.897750</td>\n",
       "      <td>236.299450</td>\n",
       "      <td>0.849200</td>\n",
       "      <td>319.148850</td>\n",
       "      <td>0.954500</td>\n",
       "      <td>85097.000000</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>1.893500</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.710850</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.505350</td>\n",
       "      <td>0.973300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89018.000000</td>\n",
       "      <td>1603.212000</td>\n",
       "      <td>468.631300</td>\n",
       "      <td>257.292375</td>\n",
       "      <td>0.875100</td>\n",
       "      <td>336.661875</td>\n",
       "      <td>0.976775</td>\n",
       "      <td>93919.000000</td>\n",
       "      <td>0.753575</td>\n",
       "      <td>2.066650</td>\n",
       "      <td>0.744500</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120744.000000</td>\n",
       "      <td>2748.856900</td>\n",
       "      <td>525.728900</td>\n",
       "      <td>383.046100</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>392.091900</td>\n",
       "      <td>0.995100</td>\n",
       "      <td>126991.000000</td>\n",
       "      <td>0.820400</td>\n",
       "      <td>3.069300</td>\n",
       "      <td>0.933600</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.756100</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AREA    PERIMETER   MAJOR_AXIS   MINOR_AXIS  ECCENTRICITY  \\\n",
       "count     1718.000000  1718.000000  1718.000000  1718.000000   1718.000000   \n",
       "unique            NaN          NaN          NaN          NaN           NaN   \n",
       "top               NaN          NaN          NaN          NaN           NaN   \n",
       "freq              NaN          NaN          NaN          NaN           NaN   \n",
       "mean     79990.176368  1423.800903   446.184575   238.404956      0.840033   \n",
       "std      13075.738130   375.345641    32.531725    30.372990      0.048895   \n",
       "min      29808.000000   858.363000   320.344500   133.509600      0.504900   \n",
       "25%      71859.500000  1169.588750   426.337050   217.925450      0.817225   \n",
       "50%      79997.500000  1261.599000   448.897750   236.299450      0.849200   \n",
       "75%      89018.000000  1603.212000   468.631300   257.292375      0.875100   \n",
       "max     120744.000000  2748.856900   525.728900   383.046100      0.945400   \n",
       "\n",
       "            EQDIASQ     SOLIDITY    CONVEX_AREA       EXTENT  ASPECT_RATIO  \\\n",
       "count   1718.000000  1718.000000    1718.000000  1718.000000   1718.000000   \n",
       "unique          NaN          NaN            NaN          NaN           NaN   \n",
       "top             NaN          NaN            NaN          NaN           NaN   \n",
       "freq            NaN          NaN            NaN          NaN           NaN   \n",
       "mean     318.003064     0.940279   85048.962165     0.715327      1.897053   \n",
       "std       26.853806     0.050205   13180.036678     0.053204      0.239194   \n",
       "min      194.814600     0.588000   37935.000000     0.427200      1.158500   \n",
       "25%      302.480300     0.920025   76334.000000     0.685225      1.735225   \n",
       "50%      319.148850     0.954500   85097.000000     0.725800      1.893500   \n",
       "75%      336.661875     0.976775   93919.000000     0.753575      2.066650   \n",
       "max      392.091900     0.995100  126991.000000     0.820400      3.069300   \n",
       "\n",
       "          ROUNDNESS  COMPACTNESS  SHAPEFACTOR_1  SHAPEFACTOR_2  SHAPEFACTOR_3  \\\n",
       "count   1718.000000  1718.000000    1718.000000    1718.000000    1718.000000   \n",
       "unique          NaN          NaN            NaN            NaN            NaN   \n",
       "top             NaN          NaN            NaN            NaN            NaN   \n",
       "freq            NaN          NaN            NaN            NaN            NaN   \n",
       "mean       0.571019     0.713397       0.005698       0.003016       0.510931   \n",
       "std        0.212615     0.044681       0.000825       0.000333       0.064074   \n",
       "min        0.062800     0.476000       0.004000       0.002400       0.226600   \n",
       "25%        0.375375     0.682225       0.005200       0.002800       0.465425   \n",
       "50%        0.644100     0.710850       0.005600       0.003000       0.505350   \n",
       "75%        0.744500     0.742300       0.006100       0.003200       0.551000   \n",
       "max        0.933600     0.869500       0.013100       0.005300       0.756100   \n",
       "\n",
       "        SHAPEFACTOR_4              Class  \n",
       "count     1718.000000               1718  \n",
       "unique            NaN                  2  \n",
       "top               NaN  Kirmizi_Pistachio  \n",
       "freq              NaN                985  \n",
       "mean         0.955492                NaN  \n",
       "std          0.050951                NaN  \n",
       "min          0.620400                NaN  \n",
       "25%          0.944000                NaN  \n",
       "50%          0.973300                NaN  \n",
       "75%          0.987200                NaN  \n",
       "max          0.998900                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very quick EDA/summary on the train data\n",
    "train = pd.read_parquet(train_path)\n",
    "summary = train.describe(include='all')\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dd0a15-51d0-44a8-a2c9-81caa650e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandera as pa\n",
    "# schema = pa.infer_schema(train)\n",
    "# print(schema)\n",
    "from pandera import Check, Column, DataFrameSchema\n",
    "# define schema based on inspecting the training data above\n",
    "if not os.path.exists(input_data_schema_path):\n",
    "# if True:\n",
    "    print(\"creating schema\")\n",
    "    schema = DataFrameSchema(\n",
    "        columns={\n",
    "            \"AREA\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=100.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"PERIMETER\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=100.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"MAJOR_AXIS\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=10.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"MINOR_AXIS\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=10.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"ECCENTRICITY\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"EQDIASQ\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=100.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"SOLIDITY\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"CONVEX_AREA\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=1000.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1e6)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"EXTENT\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"ASPECT_RATIO\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=100.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"ROUNDNESS\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"COMPACTNESS\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"SHAPEFACTOR_1\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"SHAPEFACTOR_2\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"SHAPEFACTOR_3\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"SHAPEFACTOR_4\": Column(\n",
    "                dtype=\"float64\",\n",
    "                checks=[\n",
    "                    Check.greater_than_or_equal_to(min_value=0.0),\n",
    "                    Check.less_than_or_equal_to(max_value=1.0)\n",
    "                ],\n",
    "                nullable=False\n",
    "            ),\n",
    "            \"Class\": Column(\n",
    "                dtype=\"object\",\n",
    "                checks=[\n",
    "                    Check.isin(['Siit_Pistachio', 'Kirmizi_Pistachio'])\n",
    "                ],\n",
    "                nullable=False\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    print(schema)\n",
    "    schema.to_json(input_data_schema_path)\n",
    "    print(f\"wrote schema to {input_data_schema_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5145d2-5db8-454c-b47a-5312a48bf3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no errors, data looks good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Validate Data (dtypes, count nulls)\n",
    "# preprocess - feature engineering, cast class to 1/0\n",
    "# tune - hyperopt or bayes_opt\n",
    "# stash metadata/experiment results\n",
    "# train with best parameters\n",
    "# evaluate\n",
    "# run inference on dummy \"new\" data\n",
    "from pandera import DataFrameSchema\n",
    "def validate_data(in_df: pd.DataFrame, schema_file: str) -> pd.DataFrame:\n",
    "    \"\"\"check input data, count nulls, basic stats\"\"\"\n",
    "    # load schema\n",
    "    the_schema = DataFrameSchema.from_json(schema_file)\n",
    "    the_schema.validate(in_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    # summary = in_df.describe(include='all')\n",
    "    # # check for entirely missing columns\n",
    "    # entirely_missing = [x for x in in_df.columns if summary.loc['count', x] == 0]\n",
    "    # if entirely_missing:\n",
    "    #     raise ValueError(f'following columns in supplied data are missing: {entirely_missing}')\n",
    "    # # check that columns have more than one unique value\n",
    "    # single_value_columns = [x for x in in_df.columns if summary.loc['unique', column] == 1]\n",
    "    # if entirely_missing:\n",
    "    #     raise ValueError(f'following columns in supplied data are missing: {entirely_missing}')\n",
    "\n",
    "validate_data(train, input_data_schema_path)\n",
    "\n",
    "print(\"no errors, data looks good\")\n",
    "\n",
    "\n",
    "\n",
    "# train['Class'] = train.Class.astype('category')\n",
    "# train.Class.cat.codes\n",
    "\n",
    "# https://pandas.pydata.org/docs/user_guide/categorical.html#controlling-behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9725b76f-a65d-494b-83db-771a265d902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERIMETER</th>\n",
       "      <th>MAJOR_AXIS</th>\n",
       "      <th>MINOR_AXIS</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>EQDIASQ</th>\n",
       "      <th>SOLIDITY</th>\n",
       "      <th>CONVEX_AREA</th>\n",
       "      <th>EXTENT</th>\n",
       "      <th>ASPECT_RATIO</th>\n",
       "      <th>ROUNDNESS</th>\n",
       "      <th>COMPACTNESS</th>\n",
       "      <th>SHAPEFACTOR_1</th>\n",
       "      <th>SHAPEFACTOR_2</th>\n",
       "      <th>SHAPEFACTOR_3</th>\n",
       "      <th>SHAPEFACTOR_4</th>\n",
       "      <th>SOLIDITY_MAJOR</th>\n",
       "      <th>Class</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>101005.0</td>\n",
       "      <td>1382.8000</td>\n",
       "      <td>476.3697</td>\n",
       "      <td>279.0725</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>358.6134</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>106565.0</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>1.7070</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>451.503202</td>\n",
       "      <td>Siit_Pistachio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>96240.0</td>\n",
       "      <td>1427.5699</td>\n",
       "      <td>476.6801</td>\n",
       "      <td>264.1641</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>350.0522</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>99186.0</td>\n",
       "      <td>0.7946</td>\n",
       "      <td>1.8045</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.5393</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>462.522701</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>48509.0</td>\n",
       "      <td>1020.7170</td>\n",
       "      <td>439.9729</td>\n",
       "      <td>143.3477</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>248.5228</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>49537.0</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>3.0693</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.3191</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>430.821464</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>100634.0</td>\n",
       "      <td>1260.0811</td>\n",
       "      <td>481.9576</td>\n",
       "      <td>266.3690</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>357.9542</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>101396.0</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>1.8094</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>478.342918</td>\n",
       "      <td>Siit_Pistachio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>81407.0</td>\n",
       "      <td>1244.4410</td>\n",
       "      <td>497.2620</td>\n",
       "      <td>220.6327</td>\n",
       "      <td>0.8962</td>\n",
       "      <td>321.9482</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>87965.0</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>2.2538</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.4192</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>460.166255</td>\n",
       "      <td>Kirmizi_Pistachio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n",
       "1903  101005.0  1382.8000    476.3697    279.0725        0.8104  358.6134   \n",
       "1168   96240.0  1427.5699    476.6801    264.1641        0.8324  350.0522   \n",
       "716    48509.0  1020.7170    439.9729    143.3477        0.9454  248.5228   \n",
       "1570  100634.0  1260.0811    481.9576    266.3690        0.8334  357.9542   \n",
       "889    81407.0  1244.4410    497.2620    220.6327        0.8962  321.9482   \n",
       "\n",
       "      SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ROUNDNESS  COMPACTNESS  \\\n",
       "1903    0.9478     106565.0  0.7732        1.7070     0.6638       0.7528   \n",
       "1168    0.9703      99186.0  0.7946        1.8045     0.5934       0.7344   \n",
       "716     0.9792      49537.0  0.7156        3.0693     0.5851       0.5649   \n",
       "1570    0.9925     101396.0  0.7059        1.8094     0.7964       0.7427   \n",
       "889     0.9254      87965.0  0.5527        2.2538     0.6606       0.6474   \n",
       "\n",
       "      SHAPEFACTOR_1  SHAPEFACTOR_2  SHAPEFACTOR_3  SHAPEFACTOR_4  \\\n",
       "1903         0.0047         0.0028         0.5667         0.9674   \n",
       "1168         0.0050         0.0027         0.5393         0.9731   \n",
       "716          0.0091         0.0030         0.3191         0.9793   \n",
       "1570         0.0048         0.0026         0.5516         0.9981   \n",
       "889          0.0061         0.0027         0.4192         0.9447   \n",
       "\n",
       "      SOLIDITY_MAJOR              Class  Target  \n",
       "1903      451.503202     Siit_Pistachio       0  \n",
       "1168      462.522701  Kirmizi_Pistachio       1  \n",
       "716       430.821464  Kirmizi_Pistachio       1  \n",
       "1570      478.342918     Siit_Pistachio       0  \n",
       "889       460.166255  Kirmizi_Pistachio       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "def preprocess(in_raw_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"preprocess the data, do any cleaning, feature engineering, etc\"\"\"\n",
    "    out_df = in_raw_df.copy()\n",
    "\n",
    "    #cross some features\n",
    "    out_df['SOLIDITY_MAJOR'] = out_df.SOLIDITY*out_df.MAJOR_AXIS\n",
    "\n",
    "    # reorder\n",
    "    cols = [x for x in out_df.columns if x != 'Class']\n",
    "    out_df = out_df[cols + ['Class']]\n",
    "\n",
    "    # convert Class to categorical\n",
    "    class_type = CategoricalDtype(categories=['Siit_Pistachio', 'Kirmizi_Pistachio'])\n",
    "    out_df.Class = out_df.Class.astype(class_type)\n",
    "    # create a binary column\n",
    "    out_df['Target'] = out_df.Class.cat.codes\n",
    "\n",
    "    return out_df\n",
    "\n",
    "train_proc = preprocess(train)\n",
    "train_proc.head()\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd713e-a9c1-4bae-91db-caeec1078028",
   "metadata": {},
   "source": [
    "## cross validation/tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b937843-8582-43dc-be7a-cf160e9dc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from typing import Dict\n",
    "\n",
    "def cross_validate_estimator(train_X: pd.DataFrame, train_Y: pd.DataFrame, clf: sklearn.base.BaseEstimator, metrics: Dict, n_folds: int=5, cv_seed:int=23, n_jobs: int=2):\n",
    "    \"\"\"for a given set of model parameters, use cross validation to evaluate model performance\"\"\"\n",
    "    \n",
    "    # generate cv_folds\n",
    "    cv_folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=cv_seed)\n",
    "\n",
    "    results = cross_validate(clf, train_X, train_Y, cv=cv_folds, scoring=metrics, n_jobs=n_jobs)\n",
    "\n",
    "    return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ff73a28-cd4f-4d69-8484-87b8c9c9fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.12422270774841308, 0.0006541301842787217),\n",
       " 'score_time': (0.006493997573852539, 0.0003820439249120939),\n",
       " 'test_roc_auc': (0.8691124721914356, 0.010111355494033258),\n",
       " 'test_precision': (0.8864885217567421, 0.011389116123450178),\n",
       " 'test_recall': (0.8923857868020304, 0.031684236617923335),\n",
       " 'test_f1_score': (0.8889775847285855, 0.013208642189853053)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, make_scorer\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'booster': 'gbtree',\n",
    "    'n_jobs': 1,\n",
    "    'gamma': 0.01,\n",
    "    'min_child_weight': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}\n",
    "\n",
    "cv_seed = 37\n",
    "metrics = {\n",
    "    \"roc_auc\": make_scorer(roc_auc_score),\n",
    "    \"precision\": make_scorer(precision_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"f1_score\": make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "cols = train_proc.columns\n",
    "features = [x for x in cols if x not in ['Class','Target']]\n",
    "Xx = train_proc[features]\n",
    "Yy = train_proc.Target.values\n",
    "\n",
    "clf = XGBClassifier(objective='binary:logistic', eval_metric='auc', **params)\n",
    "\n",
    "results = cross_validate_estimator(Xx, Yy, clf, metrics, cv_seed=cv_seed, n_jobs=2)\n",
    "agged_results = {k:(np.mean(v), np.std(v)) for k,v in results.items()}\n",
    "\n",
    "agged_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "589da1c9-4bb0-41f7-94f6-32c336d670cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.8634   \u001b[0m | \u001b[0m0.03452  \u001b[0m | \u001b[0m0.1866   \u001b[0m | \u001b[0m3.267    \u001b[0m | \u001b[0m0.02444  \u001b[0m | \u001b[0m0.03944  \u001b[0m | \u001b[0m0.08732  \u001b[0m | \u001b[0m0.8332   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.8629   \u001b[0m | \u001b[0m0.1623   \u001b[0m | \u001b[0m0.01841  \u001b[0m | \u001b[0m4.467    \u001b[0m | \u001b[0m0.0337   \u001b[0m | \u001b[0m0.08218  \u001b[0m | \u001b[0m0.0329   \u001b[0m | \u001b[0m0.7114   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.8681   \u001b[0m | \u001b[95m0.26     \u001b[0m | \u001b[95m0.0741   \u001b[0m | \u001b[95m3.81     \u001b[0m | \u001b[95m0.02897  \u001b[0m | \u001b[95m0.0169   \u001b[0m | \u001b[95m0.08589  \u001b[0m | \u001b[95m0.8698   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.868    \u001b[0m | \u001b[0m0.2914   \u001b[0m | \u001b[0m0.1218   \u001b[0m | \u001b[0m4.909    \u001b[0m | \u001b[0m0.03675  \u001b[0m | \u001b[0m0.07028  \u001b[0m | \u001b[0m0.01743  \u001b[0m | \u001b[0m0.8794   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.8751   \u001b[0m | \u001b[95m0.0894   \u001b[0m | \u001b[95m0.08607  \u001b[0m | \u001b[95m3.01     \u001b[0m | \u001b[95m0.04259  \u001b[0m | \u001b[95m0.0528   \u001b[0m | \u001b[95m0.06727  \u001b[0m | \u001b[95m0.8956   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.8665   \u001b[0m | \u001b[0m0.2726   \u001b[0m | \u001b[0m0.2739   \u001b[0m | \u001b[0m4.051    \u001b[0m | \u001b[0m0.01624  \u001b[0m | \u001b[0m0.02628  \u001b[0m | \u001b[0m0.09577  \u001b[0m | \u001b[0m0.7824   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8681   \u001b[0m | \u001b[0m0.2595   \u001b[0m | \u001b[0m0.2049   \u001b[0m | \u001b[0m4.258    \u001b[0m | \u001b[0m0.02653  \u001b[0m | \u001b[0m0.09071  \u001b[0m | \u001b[0m0.02862  \u001b[0m | \u001b[0m0.7809   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8678   \u001b[0m | \u001b[0m0.2981   \u001b[0m | \u001b[0m0.2234   \u001b[0m | \u001b[0m3.89     \u001b[0m | \u001b[0m0.04364  \u001b[0m | \u001b[0m0.04701  \u001b[0m | \u001b[0m0.07543  \u001b[0m | \u001b[0m0.7798   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.8616   \u001b[0m | \u001b[0m0.201    \u001b[0m | \u001b[0m0.2144   \u001b[0m | \u001b[0m4.219    \u001b[0m | \u001b[0m0.0424   \u001b[0m | \u001b[0m0.02855  \u001b[0m | \u001b[0m0.02792  \u001b[0m | \u001b[0m0.8591   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.8651   \u001b[0m | \u001b[0m0.0871   \u001b[0m | \u001b[0m0.2002   \u001b[0m | \u001b[0m3.599    \u001b[0m | \u001b[0m0.01867  \u001b[0m | \u001b[0m0.04636  \u001b[0m | \u001b[0m0.03792  \u001b[0m | \u001b[0m0.7487   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8742   \u001b[0m | \u001b[0m0.2186   \u001b[0m | \u001b[0m0.2439   \u001b[0m | \u001b[0m3.573    \u001b[0m | \u001b[0m0.04407  \u001b[0m | \u001b[0m0.0684   \u001b[0m | \u001b[0m0.09759  \u001b[0m | \u001b[0m0.8835   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.8722   \u001b[0m | \u001b[0m0.0875   \u001b[0m | \u001b[0m0.1051   \u001b[0m | \u001b[0m3.508    \u001b[0m | \u001b[0m0.03248  \u001b[0m | \u001b[0m0.05424  \u001b[0m | \u001b[0m0.01801  \u001b[0m | \u001b[0m0.8052   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.8682   \u001b[0m | \u001b[0m0.07012  \u001b[0m | \u001b[0m0.1212   \u001b[0m | \u001b[0m3.483    \u001b[0m | \u001b[0m0.0452   \u001b[0m | \u001b[0m0.04909  \u001b[0m | \u001b[0m0.08001  \u001b[0m | \u001b[0m0.8535   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8662   \u001b[0m | \u001b[0m0.05678  \u001b[0m | \u001b[0m0.2035   \u001b[0m | \u001b[0m4.925    \u001b[0m | \u001b[0m0.06005  \u001b[0m | \u001b[0m0.09563  \u001b[0m | \u001b[0m0.02497  \u001b[0m | \u001b[0m0.8807   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.8667   \u001b[0m | \u001b[0m0.08307  \u001b[0m | \u001b[0m0.07514  \u001b[0m | \u001b[0m3.015    \u001b[0m | \u001b[0m0.04244  \u001b[0m | \u001b[0m0.04688  \u001b[0m | \u001b[0m0.07229  \u001b[0m | \u001b[0m0.87     \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.8739   \u001b[0m | \u001b[0m0.005291 \u001b[0m | \u001b[0m0.102    \u001b[0m | \u001b[0m3.887    \u001b[0m | \u001b[0m0.06362  \u001b[0m | \u001b[0m0.04164  \u001b[0m | \u001b[0m0.05927  \u001b[0m | \u001b[0m0.7376   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.8637   \u001b[0m | \u001b[0m0.09673  \u001b[0m | \u001b[0m0.2771   \u001b[0m | \u001b[0m3.304    \u001b[0m | \u001b[0m0.05757  \u001b[0m | \u001b[0m0.02927  \u001b[0m | \u001b[0m0.02443  \u001b[0m | \u001b[0m0.8987   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8708   \u001b[0m | \u001b[0m0.07307  \u001b[0m | \u001b[0m0.06697  \u001b[0m | \u001b[0m3.942    \u001b[0m | \u001b[0m0.01567  \u001b[0m | \u001b[0m0.09091  \u001b[0m | \u001b[0m0.03904  \u001b[0m | \u001b[0m0.7758   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8722   \u001b[0m | \u001b[0m0.1794   \u001b[0m | \u001b[0m0.2414   \u001b[0m | \u001b[0m3.094    \u001b[0m | \u001b[0m0.06544  \u001b[0m | \u001b[0m0.03002  \u001b[0m | \u001b[0m0.09125  \u001b[0m | \u001b[0m0.7365   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.8682   \u001b[0m | \u001b[0m0.06142  \u001b[0m | \u001b[0m0.1252   \u001b[0m | \u001b[0m4.322    \u001b[0m | \u001b[0m0.0407   \u001b[0m | \u001b[0m0.06824  \u001b[0m | \u001b[0m0.04096  \u001b[0m | \u001b[0m0.7639   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.8693   \u001b[0m | \u001b[0m0.1367   \u001b[0m | \u001b[0m0.1309   \u001b[0m | \u001b[0m3.365    \u001b[0m | \u001b[0m0.02179  \u001b[0m | \u001b[0m0.01149  \u001b[0m | \u001b[0m0.01969  \u001b[0m | \u001b[0m0.7019   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.8665   \u001b[0m | \u001b[0m0.04684  \u001b[0m | \u001b[0m0.119    \u001b[0m | \u001b[0m3.623    \u001b[0m | \u001b[0m0.03699  \u001b[0m | \u001b[0m0.07904  \u001b[0m | \u001b[0m0.08675  \u001b[0m | \u001b[0m0.8655   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.8652   \u001b[0m | \u001b[0m0.02435  \u001b[0m | \u001b[0m0.02599  \u001b[0m | \u001b[0m4.154    \u001b[0m | \u001b[0m0.04801  \u001b[0m | \u001b[0m0.09676  \u001b[0m | \u001b[0m0.03765  \u001b[0m | \u001b[0m0.7096   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.8737   \u001b[0m | \u001b[0m0.01872  \u001b[0m | \u001b[0m0.07564  \u001b[0m | \u001b[0m3.12     \u001b[0m | \u001b[0m0.06503  \u001b[0m | \u001b[0m0.05084  \u001b[0m | \u001b[0m0.06657  \u001b[0m | \u001b[0m0.7716   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.8665   \u001b[0m | \u001b[0m0.002818 \u001b[0m | \u001b[0m0.06906  \u001b[0m | \u001b[0m4.297    \u001b[0m | \u001b[0m0.04052  \u001b[0m | \u001b[0m0.01004  \u001b[0m | \u001b[0m0.06783  \u001b[0m | \u001b[0m0.852    \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.8655   \u001b[0m | \u001b[0m0.1768   \u001b[0m | \u001b[0m0.04081  \u001b[0m | \u001b[0m3.932    \u001b[0m | \u001b[0m0.01179  \u001b[0m | \u001b[0m0.09965  \u001b[0m | \u001b[0m0.04195  \u001b[0m | \u001b[0m0.7703   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.8709   \u001b[0m | \u001b[0m0.2752   \u001b[0m | \u001b[0m0.1371   \u001b[0m | \u001b[0m3.809    \u001b[0m | \u001b[0m0.05903  \u001b[0m | \u001b[0m0.04442  \u001b[0m | \u001b[0m0.06145  \u001b[0m | \u001b[0m0.8431   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.8713   \u001b[0m | \u001b[0m0.1471   \u001b[0m | \u001b[0m0.1545   \u001b[0m | \u001b[0m3.52     \u001b[0m | \u001b[0m0.01297  \u001b[0m | \u001b[0m0.08779  \u001b[0m | \u001b[0m0.02135  \u001b[0m | \u001b[0m0.789    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.8609   \u001b[0m | \u001b[0m0.2152   \u001b[0m | \u001b[0m0.2963   \u001b[0m | \u001b[0m4.11     \u001b[0m | \u001b[0m0.03849  \u001b[0m | \u001b[0m0.03201  \u001b[0m | \u001b[0m0.04665  \u001b[0m | \u001b[0m0.7426   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.8703   \u001b[0m | \u001b[0m0.09406  \u001b[0m | \u001b[0m0.1353   \u001b[0m | \u001b[0m3.331    \u001b[0m | \u001b[0m0.03377  \u001b[0m | \u001b[0m0.07659  \u001b[0m | \u001b[0m0.09921  \u001b[0m | \u001b[0m0.8605   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.8723   \u001b[0m | \u001b[0m0.189    \u001b[0m | \u001b[0m0.0869   \u001b[0m | \u001b[0m4.977    \u001b[0m | \u001b[0m0.06468  \u001b[0m | \u001b[0m0.02002  \u001b[0m | \u001b[0m0.01677  \u001b[0m | \u001b[0m0.7799   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.8659   \u001b[0m | \u001b[0m0.28     \u001b[0m | \u001b[0m0.2086   \u001b[0m | \u001b[0m3.05     \u001b[0m | \u001b[0m0.0122   \u001b[0m | \u001b[0m0.01797  \u001b[0m | \u001b[0m0.09083  \u001b[0m | \u001b[0m0.7086   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.8651   \u001b[0m | \u001b[0m0.1562   \u001b[0m | \u001b[0m0.2509   \u001b[0m | \u001b[0m4.481    \u001b[0m | \u001b[0m0.0181   \u001b[0m | \u001b[0m0.0884   \u001b[0m | \u001b[0m0.01414  \u001b[0m | \u001b[0m0.8597   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.8593   \u001b[0m | \u001b[0m0.01729  \u001b[0m | \u001b[0m0.288    \u001b[0m | \u001b[0m4.147    \u001b[0m | \u001b[0m0.06929  \u001b[0m | \u001b[0m0.0714   \u001b[0m | \u001b[0m0.02732  \u001b[0m | \u001b[0m0.7452   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.8595   \u001b[0m | \u001b[0m0.2548   \u001b[0m | \u001b[0m0.1876   \u001b[0m | \u001b[0m4.51     \u001b[0m | \u001b[0m0.01135  \u001b[0m | \u001b[0m0.05678  \u001b[0m | \u001b[0m0.01682  \u001b[0m | \u001b[0m0.7142   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.8709   \u001b[0m | \u001b[0m0.01573  \u001b[0m | \u001b[0m0.1146   \u001b[0m | \u001b[0m4.374    \u001b[0m | \u001b[0m0.02483  \u001b[0m | \u001b[0m0.07336  \u001b[0m | \u001b[0m0.07253  \u001b[0m | \u001b[0m0.7284   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.8608   \u001b[0m | \u001b[0m0.2088   \u001b[0m | \u001b[0m0.228    \u001b[0m | \u001b[0m3.192    \u001b[0m | \u001b[0m0.02122  \u001b[0m | \u001b[0m0.04035  \u001b[0m | \u001b[0m0.05354  \u001b[0m | \u001b[0m0.8611   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.8677   \u001b[0m | \u001b[0m0.1173   \u001b[0m | \u001b[0m0.2502   \u001b[0m | \u001b[0m3.246    \u001b[0m | \u001b[0m0.06536  \u001b[0m | \u001b[0m0.01563  \u001b[0m | \u001b[0m0.01856  \u001b[0m | \u001b[0m0.8985   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.8621   \u001b[0m | \u001b[0m0.2317   \u001b[0m | \u001b[0m0.03401  \u001b[0m | \u001b[0m3.182    \u001b[0m | \u001b[0m0.02719  \u001b[0m | \u001b[0m0.0313   \u001b[0m | \u001b[0m0.0872   \u001b[0m | \u001b[0m0.7898   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.8648   \u001b[0m | \u001b[0m0.06001  \u001b[0m | \u001b[0m0.1167   \u001b[0m | \u001b[0m4.57     \u001b[0m | \u001b[0m0.021    \u001b[0m | \u001b[0m0.0256   \u001b[0m | \u001b[0m0.06908  \u001b[0m | \u001b[0m0.8163   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.8624   \u001b[0m | \u001b[0m0.02647  \u001b[0m | \u001b[0m0.2032   \u001b[0m | \u001b[0m3.335    \u001b[0m | \u001b[0m0.02969  \u001b[0m | \u001b[0m0.02845  \u001b[0m | \u001b[0m0.05022  \u001b[0m | \u001b[0m0.7496   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.8643   \u001b[0m | \u001b[0m0.1775   \u001b[0m | \u001b[0m0.2449   \u001b[0m | \u001b[0m3.159    \u001b[0m | \u001b[0m0.02361  \u001b[0m | \u001b[0m0.04874  \u001b[0m | \u001b[0m0.03785  \u001b[0m | \u001b[0m0.763    \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.8707   \u001b[0m | \u001b[0m0.1058   \u001b[0m | \u001b[0m0.03845  \u001b[0m | \u001b[0m4.69     \u001b[0m | \u001b[0m0.06721  \u001b[0m | \u001b[0m0.04756  \u001b[0m | \u001b[0m0.04113  \u001b[0m | \u001b[0m0.7982   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.8713   \u001b[0m | \u001b[0m0.08779  \u001b[0m | \u001b[0m0.1279   \u001b[0m | \u001b[0m4.886    \u001b[0m | \u001b[0m0.01893  \u001b[0m | \u001b[0m0.0101   \u001b[0m | \u001b[0m0.0728   \u001b[0m | \u001b[0m0.7584   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.864    \u001b[0m | \u001b[0m0.01658  \u001b[0m | \u001b[0m0.1591   \u001b[0m | \u001b[0m4.333    \u001b[0m | \u001b[0m0.01196  \u001b[0m | \u001b[0m0.04953  \u001b[0m | \u001b[0m0.08596  \u001b[0m | \u001b[0m0.8827   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.8666   \u001b[0m | \u001b[0m0.1295   \u001b[0m | \u001b[0m0.03791  \u001b[0m | \u001b[0m3.277    \u001b[0m | \u001b[0m0.02615  \u001b[0m | \u001b[0m0.05164  \u001b[0m | \u001b[0m0.05171  \u001b[0m | \u001b[0m0.8748   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.8621   \u001b[0m | \u001b[0m0.2087   \u001b[0m | \u001b[0m0.2491   \u001b[0m | \u001b[0m4.683    \u001b[0m | \u001b[0m0.04394  \u001b[0m | \u001b[0m0.01694  \u001b[0m | \u001b[0m0.06207  \u001b[0m | \u001b[0m0.8806   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.8678   \u001b[0m | \u001b[0m0.1046   \u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m3.351    \u001b[0m | \u001b[0m0.03173  \u001b[0m | \u001b[0m0.08491  \u001b[0m | \u001b[0m0.09202  \u001b[0m | \u001b[0m0.841    \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.8703   \u001b[0m | \u001b[0m0.06217  \u001b[0m | \u001b[0m0.09257  \u001b[0m | \u001b[0m4.989    \u001b[0m | \u001b[0m0.04924  \u001b[0m | \u001b[0m0.0527   \u001b[0m | \u001b[0m0.09863  \u001b[0m | \u001b[0m0.8954   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.8689   \u001b[0m | \u001b[0m0.2789   \u001b[0m | \u001b[0m0.1102   \u001b[0m | \u001b[0m3.064    \u001b[0m | \u001b[0m0.04551  \u001b[0m | \u001b[0m0.09509  \u001b[0m | \u001b[0m0.09868  \u001b[0m | \u001b[0m0.7013   \u001b[0m |\n",
      "=============================================================================================================\n",
      "best_result: {'target': 0.8751419547707581, 'params': {'gamma': 0.08940105020662881, 'learning_rate': 0.0860683985529506, 'max_depth': 3.010259098128914, 'min_child_weight': 0.04259215091682436, 'reg_alpha': 0.05280367303065279, 'reg_lambda': 0.06727363098143704, 'subsample': 0.8956408268164012}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours\n",
    "\n",
    "fixed_parameters = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"n_jobs\": 1,\n",
    "    'colsample_bytree': 0.3\n",
    "}\n",
    "pbounds = {\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'gamma': (0.0, 0.3),\n",
    "    'min_child_weight': (0.01, 0.07),\n",
    "    'max_depth': (3, 5),\n",
    "    'subsample': (0.7, 0.9),\n",
    "    'reg_alpha': (0.01, 0.1),\n",
    "    'reg_lambda': (0.01, 0.1)\n",
    "}\n",
    "integer_parameters = ['max_depth']\n",
    "\n",
    "def cast_integer_params(params: Dict, integer_params: List[str]):\n",
    "    \"\"\"cast floats in param values to integers\"\"\"\n",
    "    for x in integer_parameters:\n",
    "            if x in params:\n",
    "                params[x] = int(params[x])\n",
    "    return params\n",
    "    \n",
    "\n",
    "def optimise_tune(\n",
    "    train_x: pd.DataFrame,\n",
    "    train_y: pd.DataFrame,\n",
    "    pbounds: Dict, \n",
    "    fixed_parameters: Dict,\n",
    "    integer_parameters: List[str],\n",
    "    metrics: Dict, \n",
    "    cv_seed: int, \n",
    "    n_folds: int=5,\n",
    "    opt_n_init: int=10,\n",
    "    opt_n_iter: int=20\n",
    "):\n",
    "    \"\"\"use Bayesian optimisation to search for optimal model hyperparameters\"\"\"\n",
    "\n",
    "    # initialise list to hold (detailed) experiment results\n",
    "    trials = []\n",
    "    # discrete parameters need to be handled specially in bayesopt (explicitly cast to int)\n",
    "    \n",
    "\n",
    "    # function to run a trial - evaluate a given set of searchable parameters\n",
    "    def run_trial(**probe_params):\n",
    "        params = {**probe_params, **fixed_parms}\n",
    "        params = cast_integer_params(params, integer_parameters)\n",
    "        \n",
    "\n",
    "        # set up the XGBclassifier\n",
    "        clf = XGBClassifier(objective='binary:logistic', eval_metric='auc', **params)\n",
    "\n",
    "        # train/evaluate model through cross validation\n",
    "        results = cross_validate_estimator(train_x, train_y, clf, metrics, cv_seed=cv_seed, n_jobs=2)\n",
    "\n",
    "        # aggregate metrics over cv folds - gather mean and std deviation of each metric\n",
    "        agged_results = {k:(np.mean(v), np.std(v)) for k,v in results.items()}\n",
    "\n",
    "        # take the final score - the objective to be used for bayes_opt, as the lower bound of mean roc_auc (mean roc_auc minus error in mean roc_auc)\n",
    "        # This penalises cases where the mean might be high, but where there is more variation across folds (more uncertainty in how the model may generalise).\n",
    "        final_score = agged_results['test_roc_auc'][0] - agged_results['test_roc_auc'][1]/np.sqrt(n_folds)\n",
    "\n",
    "        # append all the metrics to the trial result.\n",
    "        trials.append( {\"final_score\": final_score, 'params': params, \"results\": agged_results})\n",
    "        return final_score\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f = run_trial,\n",
    "        random_state=43,\n",
    "        pbounds=pbounds,\n",
    "        verbose=2)\n",
    "\n",
    "    optimizer.maximize(init_points=10,n_iter=40)\n",
    "\n",
    "    print(f\"best_result: {optimizer.max}\")\n",
    "    return optimizer.max, trials\n",
    "\n",
    "# run the optimisation\n",
    "best_trial, cv_experiments = optimise_tune(Xx, Yy, pbounds, fixed_parameters, integer_parameters, metrics, cv_seed, n_folds=5)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0dd80-5b75-41af-b417-0605c09a0eee",
   "metadata": {},
   "source": [
    "## Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37720ee9-0e0c-42f7-a332-b991978bdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_parameters = {**(best_trial['params']),**fixed_parameters}\n",
    "final_parameters = cast_integer_params(final_parameters, integer_parameters)\n",
    "\n",
    "def train_model(\n",
    "    train_x: pd.DataFrame,\n",
    "    train_y: pd.DataFrame,\n",
    "    params: Dict\n",
    "): \n",
    "    \"\"\"Train a model on entire train set\"\"\"\n",
    "    clf = XGBClassifier(objective='binary:logistic', eval_metric='auc', **params)\n",
    "\n",
    "    model = clf.fit(train_x, train_y)\n",
    "    return model\n",
    "    \n",
    "model = train_model(Xx, Yy, final_parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15ab1896-78c9-4737-a8e1-47a7a6ceccaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': None,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.3,\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': 0.08940105020662881,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.0860683985529506,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 3,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': 0.04259215091682436,\n",
       " 'monotone_constraints': None,\n",
       " 'n_jobs': 1,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.05280367303065279,\n",
       " 'reg_lambda': 0.06727363098143704,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.8956408268164012,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065dc96-562a-4382-b65b-dd39e7174068",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78f189-c221-46a9-8c9f-3236b7873497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "# precision recall plot\n",
    "# roc curve\n",
    "# probability calibration\n",
    "# confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4536a876-2c7e-421c-adda-77dc951f6f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted_probs = model.predict_proba(Xx)[:,1]\n",
    "# train_predicted_probs[0:5]\n",
    "train_predicted_classes = model.predict(Xx)\n",
    "train_predicted_classes[0:5]\n",
    "train_predicted_labels = np.array([train_proc.Class.cat.categories[x] for x in train_predicted_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "277a6da0-98f1-4d43-b8ce-3036ccb6714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Siit_Pistachio', 'Siit_Pistachio', 'Kirmizi_Pistachio', ...,\n",
       "       'Siit_Pistachio', 'Kirmizi_Pistachio', 'Siit_Pistachio'],\n",
       "      dtype='<U17')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "267d3814-7d4f-4c57-b2c7-e10a6d4fd959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc_score': 0.9804170331230392,\n",
       " 'precision_score': 0.9203629032258065,\n",
       " 'recall_score': 0.9269035532994924,\n",
       " 'f1_score': 0.9236216489630754,\n",
       " 'accuracy_score': 0.9121071012805588}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation_metrics(predicted_probs, predicted_classes, actual_classes, prefix=None):\n",
    "    \"\"\"evaluate results\"\"\"\n",
    "    results = {}\n",
    "    prefix = '' if prefix is None else prefix\n",
    "    results[f\"{prefix}roc_auc_score\"] = roc_auc_score(actual_classes, predicted_probs)\n",
    "    results[f\"{prefix}precision_score\"] = precision_score(actual_classes, predicted_classes)\n",
    "    results[f\"{prefix}recall_score\"] = recall_score(actual_classes, predicted_classes)\n",
    "    results[f\"{prefix}f1_score\"] = f1_score(actual_classes, predicted_classes)\n",
    "    results[f\"{prefix}accuracy_score\"] = accuracy_score(actual_classes, predicted_classes)\n",
    "    return results\n",
    "\n",
    "evaluation_metrics(train_predicted_probs, train_predicted_classes, Yy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972921e-980c-41e3-97db-d7e23ceebcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train.columns:\n",
    "#     schema = schema.update_column(x, nullable=False)\n",
    "sc2 = pa.DataFrameSchema({\n",
    "    'col1': pa.Column(str, nullable=True),\n",
    "    'col2': pa.Column(int, nullable=False, unique=True)})\n",
    "print(sc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc226d-4709-495f-9173-76f95da0ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db124396-931e-48e9-acc9-2a0f04ad6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(schema.to_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e309e1-4f6c-465e-874d-4ede8b3d00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandera\n",
    "# pandera.__version__\n",
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83914719-9123-4cdc-a263-83e5878b71f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
