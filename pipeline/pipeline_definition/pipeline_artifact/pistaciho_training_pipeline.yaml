# PIPELINE DEFINITION
# Name: pistachio-training-pipeline
# Description: pipeline for training pistachio classifier
# Inputs:
#    test_split_data_fraction: float [Default: 0.2]
#    train_test_split_seed: int [Default: 37.0]
#    tuning_cv_seed: int [Default: 73.0]
#    tuning_opt_n_iter: int [Default: 200.0]
# Outputs:
#    evaluation-reporting-test_evaluation_metrics: system.ClassificationMetrics
#    evaluation-reporting-train_evaluation_metrics: system.ClassificationMetrics
#    psi-result-logging-psi_metrics: system.Metrics
components:
  comp-evaluate-trained-model:
    executorLabel: exec-evaluate-trained-model
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: dataset to be used for model inference
        model_pickle:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
          description: pickle file containing pistachio XGBClassifier
      parameters:
        dataset_desc:
          defaultValue: dataset
          description: dataset description, used in plot titles. Defaults to 'dataset'.
          isOptional: true
          parameterType: STRING
        metric_prefix:
          defaultValue: metric_
          description: string added as a prefix to metric keys. Defaults to 'metric_'.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        feature_importance_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        metric_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        roc_curve_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-evaluate-trained-model-2:
    executorLabel: exec-evaluate-trained-model-2
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: dataset to be used for model inference
        model_pickle:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
          description: pickle file containing pistachio XGBClassifier
      parameters:
        dataset_desc:
          defaultValue: dataset
          description: dataset description, used in plot titles. Defaults to 'dataset'.
          isOptional: true
          parameterType: STRING
        metric_prefix:
          defaultValue: metric_
          description: string added as a prefix to metric keys. Defaults to 'metric_'.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        feature_importance_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        metric_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        roc_curve_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-evaluation-reporting:
    executorLabel: exec-evaluation-reporting
    inputDefinitions:
      artifacts:
        feature_importance_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        test_evaluation_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
          description: _description_
        test_roc_curve_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        train_evaluation_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        train_roc_curve_plot_png:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        evaluation_markdown:
          artifactType:
            schemaTitle: system.Markdown
            schemaVersion: 0.0.1
        test_evaluation_metrics:
          artifactType:
            schemaTitle: system.ClassificationMetrics
            schemaVersion: 0.0.1
        train_evaluation_metrics:
          artifactType:
            schemaTitle: system.ClassificationMetrics
            schemaVersion: 0.0.1
  comp-hyperparameter-tuning:
    executorLabel: exec-hyperparameter-tuning
    inputDefinitions:
      artifacts:
        preprocessed_train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: path to preprocessed training dataset (parquet)
      parameters:
        colsample_bytree_bounds:
          defaultValue:
          - 0.1
          - 0.5
          isOptional: true
          parameterType: LIST
        cv_n_folds:
          defaultValue: 5.0
          description: number of folds for cross validation. Defaults to 5.
          isOptional: true
          parameterType: NUMBER_INTEGER
        cv_seed:
          defaultValue: 43.0
          description: seed used for splitting fold definition in cross validation.
            Defaults to 43.
          isOptional: true
          parameterType: NUMBER_INTEGER
        gamma_bounds:
          defaultValue:
          - 0.0
          - 0.3
          isOptional: true
          parameterType: LIST
        learning_rate_bounds:
          defaultValue:
          - 0.01
          - 0.3
          isOptional: true
          parameterType: LIST
        max_depth_bounds:
          defaultValue:
          - 3.0
          - 5.0
          isOptional: true
          parameterType: LIST
        min_child_weight_bounds:
          defaultValue:
          - 0.01
          - 0.07
          isOptional: true
          parameterType: LIST
        opt_n_init:
          defaultValue: 10.0
          description: number of initial (random) trials, prior to optimised searching.
            Defaults to 10.
          isOptional: true
          parameterType: NUMBER_INTEGER
        opt_n_iter:
          defaultValue: 200.0
          description: number of search trials to run. Defaults to 200.
          isOptional: true
          parameterType: NUMBER_INTEGER
        opt_random_seed:
          defaultValue: 73.0
          description: random seed to be used during search process. Defaults to 73.
          isOptional: true
          parameterType: NUMBER_INTEGER
        reg_alpha_bounds:
          defaultValue:
          - 0.01
          - 0.1
          isOptional: true
          parameterType: LIST
        reg_lambda_bounds:
          defaultValue:
          - 0.01
          - 0.1
          isOptional: true
          parameterType: LIST
        subsample_bounds:
          defaultValue:
          - 0.7
          - 0.9
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        optimal_parameters_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        tuning_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-infer-monitoring:
    executorLabel: exec-infer-monitoring
    inputDefinitions:
      artifacts:
        inference_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: Dataset to be used for model inference
        psi_artifact:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
          description: PSI object containing statistics computed at training time
    outputDefinitions:
      artifacts:
        psi_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-load-data:
    executorLabel: exec-load-data
    inputDefinitions:
      parameters:
        input_file_path:
          description: _description_
          parameterType: STRING
        label_column:
          defaultValue: Class
          description: Label column in that dataset - used to stratify the splitting.
            Defaults to 'Class'.
          isOptional: true
          parameterType: STRING
        split_seed:
          defaultValue: 37.0
          description: seed used when carrying out train/test split. Defaults to 37.
          isOptional: true
          parameterType: NUMBER_INTEGER
        test_fraction:
          defaultValue: 0.2
          description: fraction of data to be allocated to test split. Defaults to
            0.2.
          isOptional: true
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        output_test:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        output_train:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-preprocess-data:
    executorLabel: exec-preprocess-data
    inputDefinitions:
      artifacts:
        input_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: path to raw data to be preprocessed
    outputDefinitions:
      artifacts:
        output_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-preprocess-data-2:
    executorLabel: exec-preprocess-data-2
    inputDefinitions:
      artifacts:
        input_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: path to raw data to be preprocessed
    outputDefinitions:
      artifacts:
        output_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-psi-result-logging:
    executorLabel: exec-psi-result-logging
    inputDefinitions:
      artifacts:
        psi_results_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
          description: Json output produced when running psi evaluation
      parameters:
        md_note:
          defaultValue: ''
          description: optional note/text to include in markdown
          isOptional: true
          parameterType: STRING
        metric_prefix:
          defaultValue: psi_value
          description: _description_. Defaults to 'psi_value'.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        psi_markdown:
          artifactType:
            schemaTitle: system.Markdown
            schemaVersion: 0.0.1
        psi_metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-train-final-model:
    executorLabel: exec-train-final-model
    inputDefinitions:
      artifacts:
        optimal_parameters_json:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
          description: parameters to use for the final model
        preprocessed_train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: preprocessed training data
    outputDefinitions:
      artifacts:
        model_pickle:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-train-monitoring:
    executorLabel: exec-train-monitoring
    inputDefinitions:
      artifacts:
        train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: preprocessed training data
    outputDefinitions:
      artifacts:
        psi_artifact:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-validate-data:
    executorLabel: exec-validate-data
    inputDefinitions:
      artifacts:
        input_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: path to input dataset to be validated
      parameters:
        schema_file_path:
          description: pandera schema file to use for validation
          parameterType: STRING
  comp-validate-data-2:
    executorLabel: exec-validate-data-2
    inputDefinitions:
      artifacts:
        input_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
          description: path to input dataset to be validated
      parameters:
        schema_file_path:
          description: pandera schema file to use for validation
          parameterType: STRING
defaultPipelineRoot: gs://pistachio_pipeline_sbx_bucket/pistachio_pipeline_root
deploymentSpec:
  executors:
    exec-evaluate-trained-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_trained_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_trained_model(\n    dataset: Input[Dataset],\n    model_pickle:\
          \ Input[Model],\n    metric_results_json: Output[Artifact],\n    feature_importance_plot_png:\
          \ Output[Artifact],\n    roc_curve_plot_png: Output[Artifact],\n    metric_prefix:\
          \ str='metric_',\n    dataset_desc: str='dataset'\n    ) -> None:\n    \"\
          \"\"evaluate trained model on specified dataset\n\n    Args:\n        dataset\
          \ (Input[Dataset]): dataset to be used for model inference\n        model_pickle\
          \ (Input[Model]): pickle file containing pistachio XGBClassifier\n     \
          \   metric_results_json (Output[Artifact]): location where evaluation metrics\
          \ will be written (as json)\n        feature_importance_plot_png (Output[Artifact]):\
          \ path where feature importance plot will be written as png\n        roc_curve_plot_png\
          \ (Output[Artifact]): path where roc curve plot will be written as png\n\
          \        metric_prefix (str, optional): string added as a prefix to metric\
          \ keys. Defaults to 'metric_'.\n        dataset_desc (str, optional): dataset\
          \ description, used in plot titles. Defaults to 'dataset'.\n\n    Returns:\n\
          \       None\n    \"\"\"\n    from evaluate_model import evaluate_model_features\n\
          \    features = dataset.metadata['features']\n\n    metric_results_json.path\
          \ = metric_results_json.path + '.json'\n    feature_importance_plot_png.path\
          \ = feature_importance_plot_png.path + '.png'\n    roc_curve_plot_png.path\
          \ = roc_curve_plot_png.path + '.png'\n\n    evaluate_model_features(\n \
          \   dataset_path=dataset.path,\n    model_pickle_path=model_pickle.path,\n\
          \    features=features,\n    metric_results_json=metric_results_json.path,\n\
          \    feature_importance_plot_png=feature_importance_plot_png.path,\n   \
          \ roc_curve_plot_png=roc_curve_plot_png.path,\n    metric_prefix=metric_prefix,\n\
          \    dataset_desc=dataset_desc)\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-evaluate-trained-model-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_trained_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_trained_model(\n    dataset: Input[Dataset],\n    model_pickle:\
          \ Input[Model],\n    metric_results_json: Output[Artifact],\n    feature_importance_plot_png:\
          \ Output[Artifact],\n    roc_curve_plot_png: Output[Artifact],\n    metric_prefix:\
          \ str='metric_',\n    dataset_desc: str='dataset'\n    ) -> None:\n    \"\
          \"\"evaluate trained model on specified dataset\n\n    Args:\n        dataset\
          \ (Input[Dataset]): dataset to be used for model inference\n        model_pickle\
          \ (Input[Model]): pickle file containing pistachio XGBClassifier\n     \
          \   metric_results_json (Output[Artifact]): location where evaluation metrics\
          \ will be written (as json)\n        feature_importance_plot_png (Output[Artifact]):\
          \ path where feature importance plot will be written as png\n        roc_curve_plot_png\
          \ (Output[Artifact]): path where roc curve plot will be written as png\n\
          \        metric_prefix (str, optional): string added as a prefix to metric\
          \ keys. Defaults to 'metric_'.\n        dataset_desc (str, optional): dataset\
          \ description, used in plot titles. Defaults to 'dataset'.\n\n    Returns:\n\
          \       None\n    \"\"\"\n    from evaluate_model import evaluate_model_features\n\
          \    features = dataset.metadata['features']\n\n    metric_results_json.path\
          \ = metric_results_json.path + '.json'\n    feature_importance_plot_png.path\
          \ = feature_importance_plot_png.path + '.png'\n    roc_curve_plot_png.path\
          \ = roc_curve_plot_png.path + '.png'\n\n    evaluate_model_features(\n \
          \   dataset_path=dataset.path,\n    model_pickle_path=model_pickle.path,\n\
          \    features=features,\n    metric_results_json=metric_results_json.path,\n\
          \    feature_importance_plot_png=feature_importance_plot_png.path,\n   \
          \ roc_curve_plot_png=roc_curve_plot_png.path,\n    metric_prefix=metric_prefix,\n\
          \    dataset_desc=dataset_desc)\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-evaluation-reporting:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluation_reporting
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluation_reporting(\n    train_evaluation_results_json: Input[Artifact],\n\
          \    test_evaluation_results_json: Input[Artifact],\n    feature_importance_plot_png:\
          \ Input[Artifact],\n    train_roc_curve_plot_png: Input[Artifact],\n   \
          \ test_roc_curve_plot_png: Input[Artifact],\n    evaluation_markdown: Output[Markdown],\n\
          \    # evaluation_metrics: Output[SlicedClassificationMetrics] # SlicedClassificationMetrics\
          \ is buggy\n    train_evaluation_metrics: Output[ClassificationMetrics],\n\
          \    test_evaluation_metrics: Output[ClassificationMetrics],\n    ):\n \
          \   \"\"\"evaluation_reporting\n        Generate markdown output and log\
          \ metrics from json files containing evaluation results\n\n\n    Args:\n\
          \        train_evalution_results_json (Input[Artifact]): _description_\n\
          \        test_evaluation_results_json (Input[Artifact]): _description_\n\
          \        feaure_importance_plot_png (Input[Artifact]): _description_\n \
          \       evaluation_markdown (Output[Markdown]): _description_\n        evaluation_metrics\
          \ (Output[SlicedClassificationMetrics]): _description_\n    \"\"\"\n\n \
          \   import json\n    import os\n    import logging\n    import sys\n\n \
          \   logger = logging.getLogger('pistachio.evaluation_reporting')\n    logging.basicConfig(stream=sys.stdout,\
          \ level=logging.DEBUG)\n\n    evaluation_markdown.path = evaluation_markdown.path\
          \ + '.md'\n\n\n    # load the json content\n    with open(test_evaluation_results_json.path,'r')\
          \ as infile:\n        test_results = json.load(infile)\n    with open(train_evaluation_results_json.path,'r')\
          \ as infile:\n        train_results = json.load(infile)\n\n    # setup a\
          \ string for markdown content\n    # include a table header\n    markdown_content\
          \ = f\"# Pistachio Classifier Evaluation Results\\n\\n## Feature Importance\\\
          n\\n![Feature Importance png]({feature_importance_plot_png.uri})\\n\\n\"\
          \n    # Population Stability Index evaluation\\n\\n{md_note}\\n\\n\" + \\\
          \n    #     \"| Column | Datatype | Missing Values | PSI |\\n|--------|----------|----------------|-----|\\\
          n\"\n\n\n    markdown_content += '## Train Set Metrics\\n\\n| *Metric* |\
          \ *Value* |\\n|--------|--------|\\n'\n\n    # Train result metrics\n  \
          \  for k,v in train_results['metrics'].items():\n        markdown_content\
          \ += f'| {k} | {v} |\\n'\n        # try this\n        # train_evaluation_metrics.metadata[k]\
          \ = v\n\n\n    markdown_content += f'\\n ## Train Set ROC curve\\n\\n![Train\
          \ Set ROC curve png]({train_roc_curve_plot_png.uri})\\n\\n'\n\n    markdown_content\
          \ += '## Test Set Metrics\\n\\n| *Metric* | *Value* |\\n|--------|--------|\\\
          n'\n    # test result metrics\n    for k,v in test_results['metrics'].items():\n\
          \        markdown_content += f'| {k} | {v} |\\n'\n        # try this\n \
          \       # test_evaluation_metrics.metadata[k] = v\n    markdown_content\
          \ += f'\\n ## Test Set ROC curve\\n\\n![Test Set ROC curve png]({test_roc_curve_plot_png.uri})\\\
          n\\n'\n\n    # sliced metrics - this is buggy at present\n    # evaluation_metrics._sliced_metrics\
          \ = {}\n    # get roc curve definition\n\n    # test_roc_curve_definition\
          \ = [\n    #     test_results['roc_curve']['thresholds'],\n    #     test_results['roc_curve']['tpr'],\n\
          \    #     test_results['roc_curve']['fpr']]\n\n    # evaluation_metrics.load_roc_readings('test',\
          \ test_roc_curve_definition)\n    # hack\n    test_results['roc_curve']['thresholds'][0]\
          \ = 1.0e9\n\n    test_evaluation_metrics.log_roc_curve(\n        test_results['roc_curve']['fpr'],\n\
          \        test_results['roc_curve']['tpr'],\n        test_results['roc_curve']['thresholds'])\n\
          \n    # train_evaluation_metrics.log_roc_curve(\n    #     train_results['roc_curve']['fpr'],\n\
          \    #     train_results['roc_curve']['tpr'],\n    #     train_results['roc_curve']['thresholds'])\n\
          \n    # dummy roc data\n    fpr = [ 0.0, 0.0, 0.0, 1.0]\n    tpr = [0.0,\
          \ 0.5, 1.0, 1.0]\n    thresholds = [sys.float_info.max, 0.99, 0.8, 0.01]\
          \ # infinity is an issue\n    # test_evaluation_metrics.log_roc_curve(fpr,\
          \ tpr, thresholds)\n    train_evaluation_metrics.log_roc_curve(fpr, tpr,\
          \ thresholds)\n\n\n\n    # write markdown content\n    output_dir = os.path.dirname(evaluation_markdown.path)\n\
          \    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\
          \    with open(evaluation_markdown.path,'w') as outfile:\n        outfile.write(markdown_content)\n\
          \        logger.info(f'markdown written to {evaluation_markdown.path}')\n\
          \    logger.info('done model evaluation reporting')\n\n"
        image: python:3.11
    exec-hyperparameter-tuning:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - hyperparameter_tuning
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef hyperparameter_tuning(\n    preprocessed_train_data: Input[Dataset],\n\
          \    tuning_results_json: Output[Artifact],\n    optimal_parameters_json:\
          \ Output[Artifact],\n    cv_seed: int=43,\n    cv_n_folds: int=5,\n    opt_n_init:\
          \ int=10,\n    opt_n_iter: int=200,\n    opt_random_seed: int=73,\n    learning_rate_bounds:\
          \ List[float]=[0.01, 0.3],\n    gamma_bounds: List[float]=[0.0, 0.3],\n\
          \    min_child_weight_bounds: List[float]=[0.01, 0.07],\n    max_depth_bounds:\
          \ List[int]=[3, 5],\n    subsample_bounds: List[float]=[0.7, 0.9],\n   \
          \ reg_alpha_bounds: List[float]=[0.01, 0.1],\n    reg_lambda_bounds: List[float]=[0.01,\
          \ 0.1],\n    colsample_bytree_bounds: List[float]=[0.1, 0.5]\n    ) -> None:\n\
          \    \"\"\"hyperparameter tuning component\n    tunes an CGB classifier\
          \ using bayesopt to search hyperparameter space\n\n    Args:\n        preprocessed_train_data\
          \ (Input[Dataset]): path to preprocessed training dataset (parquet)\n  \
          \      tuning_results_json (Output[Artifact]): output path for tuning results/details\
          \ (json)\n        optimal_parameters_json (Output[Artifact]): output path\
          \ to best parameter set found (json)\n        cv_seed (int, optional): seed\
          \ used for splitting fold definition in cross validation. Defaults to 43.\n\
          \        cv_n_folds (int, optional): number of folds for cross validation.\
          \ Defaults to 5.\n        opt_n_init (int, optional): number of initial\
          \ (random) trials, prior to optimised searching. Defaults to 10.\n     \
          \   opt_n_iter (int, optional): number of search trials to run. Defaults\
          \ to 200.\n        opt_random_seed (int, optional): random seed to be used\
          \ during search process. Defaults to 73.\n\n    Returns:\n        None\n\
          \    \"\"\"\n    from model_tuning import model_tune_features\n    tuning_results_json.path\
          \ = tuning_results_json.path + '.json'\n    optimal_parameters_json.path\
          \ = optimal_parameters_json.path + '.json'\n\n    pbounds = {\n        'learning_rate':\
          \ (learning_rate_bounds[0], learning_rate_bounds[1]),\n        'gamma':\
          \ (gamma_bounds[0], gamma_bounds[1]),\n        'min_child_weight': (min_child_weight_bounds[0],\
          \ min_child_weight_bounds[1]),\n        'max_depth': (max_depth_bounds[0],\
          \ max_depth_bounds[1]),\n        'subsample': (subsample_bounds[0], subsample_bounds[1]),\n\
          \        'reg_alpha': (reg_alpha_bounds[0], reg_alpha_bounds[1]),\n    \
          \    'reg_lambda': (reg_lambda_bounds[0], reg_lambda_bounds[1]),\n     \
          \   'colsample_bytree': (colsample_bytree_bounds[0], colsample_bytree_bounds[1])\n\
          \    }\n\n    features = preprocessed_train_data.metadata['features']\n\
          \    model_tune_features(\n        train_file=preprocessed_train_data.path,\n\
          \        features=features,\n        tune_results_json=tuning_results_json.path,\n\
          \        optimal_parameters_json=optimal_parameters_json.path,\n       \
          \ pbounds=pbounds,\n        cv_seed=cv_seed,\n        n_folds=cv_n_folds,\n\
          \        opt_n_init=opt_n_init,\n        opt_n_iter=opt_n_iter,\n      \
          \  opt_random_seed=opt_random_seed\n    )\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-infer-monitoring:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - infer_monitoring
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef infer_monitoring(\n    inference_data: Input[Dataset],\n    psi_artifact:\
          \ Input[Artifact],\n    psi_results_json: Output[Artifact]\n    ) -> None:\n\
          \    \"\"\"inference monitoring component\n    check for data drift when\
          \ running inference\n\n    Args:\n        inference_data (Input[Dataset]):\
          \ Dataset to be used for model inference\n        psi_artifact (Input[Artifact]):\
          \ PSI object containing statistics computed at training time\n        psi_results_json\
          \ (Output[Artifact]): PSI results as json file\n\n    Returns:\n       \
          \ None\n    \"\"\"\n\n    from infer_monitoring import eval_psi\n    from\
          \ pistachio.data_handling import read_from_json\n\n    psi_results_json.path\
          \ = psi_results_json.path + '.json'\n\n    eval_psi(inference_data.path,\
          \ psi_artifact.path, psi_results_json.path)\n    # attach psi results as\
          \ metadata\n    psi_results = read_from_json(psi_results_json.path)\n  \
          \  inference_data.metadata['psi_evaluation_results'] = psi_results\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(input_file_path: str,\n    output_train: Output[Dataset],\n\
          \    output_test: Output[Dataset],\n    split_seed: int=37,\n    test_fraction:\
          \ float=0.2,\n    label_column: str='Class'\n    )-> None:\n    \"\"\"load_data\n\
          \    component to load data from arff file and write to parquet\n\n    Args:\n\
          \        input_file_path (str): _description_\n        output_train (Output[Dataset]):\
          \ path train data will be written to\n        output_test (Output[Dataset]):\
          \ path test data will be written to \n        split_seed (int, optional):\
          \ seed used when carrying out train/test split. Defaults to 37.\n      \
          \  test_fraction (float, optional): fraction of data to be allocated to\
          \ test split. Defaults to 0.2.\n        label_column (str, optional): Label\
          \ column in that dataset - used to stratify the splitting. Defaults to 'Class'.\n\
          \n    Returns:\n        None\n    \"\"\"\n\n    from load_data import load_and_split_data\n\
          \    # load_data.py is the python file in the image - the container components\
          \ run this as an entrypoint\n\n    output_train.path = output_train.path\
          \ + '.pqt'\n    output_test.path = output_test.path + '.pqt'\n\n    load_and_split_data(\n\
          \        input_file_path=input_file_path,\n        output_train_file_path=output_train.path,\n\
          \        output_test_file_path=output_test.path,\n        split_seed=split_seed,\n\
          \        test_fraction=test_fraction,\n        label_column=label_column\n\
          \    )\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-preprocess-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess_data(\n    input_file: Input[Dataset],\n    output_file:\
          \ Output[Dataset],\n    )-> None:\n    \"\"\"preprocess_data component\n\
          \n    Args:\n        input_file (Input[Dataset]): path to raw data to be\
          \ preprocessed\n        output_file (Output[Dataset]): path where preprocessed\
          \ data will be written \n        feature_list (Output[Artifact]): path to\
          \ where list of feature columns will be written as json\n\n    Returns:\n\
          \        None\n    \"\"\"   \n    from preprocess_data import preprocess_data_features\n\
          \n    output_file.path = output_file.path + '.pqt'\n\n    features = preprocess_data_features(\
          \ input_file.path, output_file.path)\n    output_file.metadata['features']\
          \ = features\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-preprocess-data-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess_data(\n    input_file: Input[Dataset],\n    output_file:\
          \ Output[Dataset],\n    )-> None:\n    \"\"\"preprocess_data component\n\
          \n    Args:\n        input_file (Input[Dataset]): path to raw data to be\
          \ preprocessed\n        output_file (Output[Dataset]): path where preprocessed\
          \ data will be written \n        feature_list (Output[Artifact]): path to\
          \ where list of feature columns will be written as json\n\n    Returns:\n\
          \        None\n    \"\"\"   \n    from preprocess_data import preprocess_data_features\n\
          \n    output_file.path = output_file.path + '.pqt'\n\n    features = preprocess_data_features(\
          \ input_file.path, output_file.path)\n    output_file.metadata['features']\
          \ = features\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-psi-result-logging:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - psi_result_logging
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef psi_result_logging(\n    psi_results_json: Input[Artifact],\n\
          \    psi_markdown: Output[Markdown],\n    psi_metrics: Output[Metrics],\n\
          \    md_note: str = '',\n    metric_prefix: str = 'psi_value'\n    ):\n\
          \    \"\"\"psi_result_logging\n    Generate markdown output and log metrics\
          \ from json file containing psi_results\n\n    Args:\n        psi_results_json\
          \ (Input[Artifact]): Json output produced when running psi evaluation\n\
          \        psi_markdown (Output[Markdown]): output markdown content\n    \
          \    psi_metrics (Output[Metrics]): output metric artifact - psi details\
          \ will be logged to this\n        md_note (str): optional note/text to include\
          \ in markdown\n        metric_prefix (str, optional): _description_. Defaults\
          \ to 'psi_value'.\n\n    Returns:\n        dsl.ContainerSpec: component\
          \ definition\n    \"\"\"\n\n    psi_markdown.path = psi_markdown.path +\
          \ '.md'\n\n    import json\n    import os\n    import logging\n    import\
          \ sys\n    logger = logging.getLogger('pistachio.psi_result_logging')\n\
          \    logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n\n\n \
          \   # load the json content\n    with open(psi_results_json.path,'r') as\
          \ infile:\n        psi_details = json.load(infile)\n\n    # setup a string\
          \ for markdown content\n    # include a table header\n    markdown_content\
          \ = f\"# PSI results\\nPopulation Stability Index evaluation\\n\\n{md_note}\\\
          n\\n\" + \\\n        \"| Column | Datatype | Missing Values | PSI |\\n|--------|----------|----------------|-----|\\\
          n\"\n\n    # log psi metrics\n    for column_name in psi_details.keys():\n\
          \        the_dtype = psi_details[column_name].get('datatype','unknown')\n\
          \        n_missing = psi_details[column_name].get('eval_missing',' ')\n\
          \        psi_value = psi_details[column_name].get('PSI','')\n        table_content\
          \ = f'| {column_name} | {the_dtype} | {n_missing} | {psi_value} |\\n'\n\n\
          \        # add to table\n        markdown_content += table_content\n\n \
          \       metric_name = f'{metric_prefix}_{column_name}'\n        try:\n \
          \           psi_metrics.log_metric(metric_name, float(psi_value))\n    \
          \        logger.info(f'logged {metric_name} to metrics')\n        except\
          \ Exception as e:\n            logger.warning(f'could not log {metric_name}\
          \ with value \"{psi_value}\" ')\n\n    # write markdown content\n    output_dir\
          \ = os.path.dirname(psi_markdown.path)\n    if not os.path.exists(output_dir):\n\
          \        os.makedirs(output_dir)\n    with open(psi_markdown.path,'w') as\
          \ outfile:\n        outfile.write(markdown_content)\n        logger.info(f'markdown\
          \ written to {psi_markdown.path}')\n    logger.info('done psi result logging')\n\
          \n"
        image: python:3.11
    exec-train-final-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_final_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_final_model(\n    preprocessed_train_data: Input[Dataset],\n\
          \    optimal_parameters_json: Input[Artifact],\n    model_pickle: Output[Model],\n\
          \    ) -> None:\n    \"\"\"model training component\n\n    trains a model\
          \ and saves it as an artifact (pickle file) based on the parameters obtained\
          \ from tuning\n\n    Args:\n        preprocessed_train_data (Input[Dataset]):\
          \ preprocessed training data\n        optimal_parameters_json (Input[Artifact]):\
          \ parameters to use for the final model\n        model_pickle (Output[Model]):\
          \ trained model artifact\n\n    Returns:\n        None\n    \"\"\"\n   \
          \ from train_model import train_final_model_features\n\n    model_pickle.path\
          \ = model_pickle.path + '.pkl'\n    features = preprocessed_train_data.metadata['features']\n\
          \n    train_final_model_features(\n        training_data_path=preprocessed_train_data.path,\n\
          \        optimal_parameters_json_path=optimal_parameters_json.path,\n  \
          \      output_model_artifact_path=model_pickle.path,\n        features=features\n\
          \    )\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-train-monitoring:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_monitoring
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_monitoring(\n    train_data: Input[Dataset],\n    psi_artifact:\
          \ Output[Artifact]\n    ) -> None:\n    \"\"\"train_monitoring component\n\
          \n    Args:\n        train_data (Input[Dataset]): preprocessed training\
          \ data\n        psi_artifact (Output[Artifact]): PSI artifact containing\
          \ trained PSIMetrics object\n\n    Returns:\n        None\n    \"\"\"\n\n\
          \    from train_monitoring import fit_psi\n\n    psi_artifact.path = psi_artifact.path\
          \ + '.pkl'\n    fit_psi(train_data.path, psi_artifact.path)\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-validate-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_data(\n    input_file: Input[Dataset],\n    schema_file_path:\
          \ str\n    )-> None:\n    \"\"\"validate_data component\n\n    Args:\n \
          \       input_file (Input[Dataset]): path to input dataset to be validated\n\
          \        schema_file_path (str): pandera schema file to use for validation\n\
          \n    Returns:\n        None\n    \"\"\"\n    from validate_data import\
          \ validate_data\n    validate_data(input_file.path, schema_file_path)\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
    exec-validate-data-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.3.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_data(\n    input_file: Input[Dataset],\n    schema_file_path:\
          \ str\n    )-> None:\n    \"\"\"validate_data component\n\n    Args:\n \
          \       input_file (Input[Dataset]): path to input dataset to be validated\n\
          \        schema_file_path (str): pandera schema file to use for validation\n\
          \n    Returns:\n        None\n    \"\"\"\n    from validate_data import\
          \ validate_data\n    validate_data(input_file.path, schema_file_path)\n\n"
        image: northamerica-northeast2-docker.pkg.dev/pistachio-mlops-sbx/pistachio-base/pistachio_base:0.0.1
pipelineInfo:
  description: pipeline for training pistachio classifier
  name: pistachio-training-pipeline
root:
  dag:
    outputs:
      artifacts:
        evaluation-reporting-test_evaluation_metrics:
          artifactSelectors:
          - outputArtifactKey: test_evaluation_metrics
            producerSubtask: evaluation-reporting
        evaluation-reporting-train_evaluation_metrics:
          artifactSelectors:
          - outputArtifactKey: train_evaluation_metrics
            producerSubtask: evaluation-reporting
        psi-result-logging-psi_metrics:
          artifactSelectors:
          - outputArtifactKey: psi_metrics
            producerSubtask: psi-result-logging
    tasks:
      evaluate-trained-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-trained-model
        dependentTasks:
        - preprocess-data
        - train-final-model
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data
            model_pickle:
              taskOutputArtifact:
                outputArtifactKey: model_pickle
                producerTask: train-final-model
          parameters:
            dataset_desc:
              runtimeValue:
                constant: Training Data
            metric_prefix:
              runtimeValue:
                constant: train_metrics
        taskInfo:
          name: model evaluation - training data
      evaluate-trained-model-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-trained-model-2
        dependentTasks:
        - preprocess-data-2
        - train-final-model
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data-2
            model_pickle:
              taskOutputArtifact:
                outputArtifactKey: model_pickle
                producerTask: train-final-model
          parameters:
            dataset_desc:
              runtimeValue:
                constant: Test Data
            metric_prefix:
              runtimeValue:
                constant: test_metrics
        taskInfo:
          name: model evaluation - test data
      evaluation-reporting:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluation-reporting
        dependentTasks:
        - evaluate-trained-model
        - evaluate-trained-model-2
        inputs:
          artifacts:
            feature_importance_plot_png:
              taskOutputArtifact:
                outputArtifactKey: feature_importance_plot_png
                producerTask: evaluate-trained-model
            test_evaluation_results_json:
              taskOutputArtifact:
                outputArtifactKey: metric_results_json
                producerTask: evaluate-trained-model-2
            test_roc_curve_plot_png:
              taskOutputArtifact:
                outputArtifactKey: roc_curve_plot_png
                producerTask: evaluate-trained-model-2
            train_evaluation_results_json:
              taskOutputArtifact:
                outputArtifactKey: metric_results_json
                producerTask: evaluate-trained-model
            train_roc_curve_plot_png:
              taskOutputArtifact:
                outputArtifactKey: roc_curve_plot_png
                producerTask: evaluate-trained-model
        taskInfo:
          name: log evaluation results
      hyperparameter-tuning:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-hyperparameter-tuning
        dependentTasks:
        - preprocess-data
        inputs:
          artifacts:
            preprocessed_train_data:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data
          parameters:
            cv_seed:
              componentInputParameter: tuning_cv_seed
            opt_n_iter:
              componentInputParameter: tuning_opt_n_iter
        taskInfo:
          name: hyperparameter tuning
      infer-monitoring:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-infer-monitoring
        dependentTasks:
        - preprocess-data-2
        - train-monitoring
        inputs:
          artifacts:
            inference_data:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data-2
            psi_artifact:
              taskOutputArtifact:
                outputArtifactKey: psi_artifact
                producerTask: train-monitoring
        taskInfo:
          name: test data PSI monitoring
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        inputs:
          parameters:
            input_file_path:
              runtimeValue:
                constant: /gcs/pistachio_pipeline_sbx_bucket/pipeline_resources/Pistachio_16_Features_Dataset.arff
            label_column:
              runtimeValue:
                constant: Class
            split_seed:
              componentInputParameter: train_test_split_seed
            test_fraction:
              componentInputParameter: test_split_data_fraction
        taskInfo:
          name: load-data
      preprocess-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess-data
        dependentTasks:
        - load-data
        - validate-data
        inputs:
          artifacts:
            input_file:
              taskOutputArtifact:
                outputArtifactKey: output_train
                producerTask: load-data
        taskInfo:
          name: preprocess train data
      preprocess-data-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess-data-2
        dependentTasks:
        - load-data
        - validate-data-2
        inputs:
          artifacts:
            input_file:
              taskOutputArtifact:
                outputArtifactKey: output_test
                producerTask: load-data
        taskInfo:
          name: preprocess test data
      psi-result-logging:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-psi-result-logging
        dependentTasks:
        - infer-monitoring
        inputs:
          artifacts:
            psi_results_json:
              taskOutputArtifact:
                outputArtifactKey: psi_results_json
                producerTask: infer-monitoring
          parameters:
            md_note:
              runtimeValue:
                constant: logging PSI metrics at training time on test dataset
        taskInfo:
          name: data monitoring - log results
      train-final-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-final-model
        dependentTasks:
        - hyperparameter-tuning
        - preprocess-data
        inputs:
          artifacts:
            optimal_parameters_json:
              taskOutputArtifact:
                outputArtifactKey: optimal_parameters_json
                producerTask: hyperparameter-tuning
            preprocessed_train_data:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data
        taskInfo:
          name: model training
      train-monitoring:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-monitoring
        dependentTasks:
        - preprocess-data
        inputs:
          artifacts:
            train_data:
              taskOutputArtifact:
                outputArtifactKey: output_file
                producerTask: preprocess-data
        taskInfo:
          name: compute monitoring statistics
      validate-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-validate-data
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            input_file:
              taskOutputArtifact:
                outputArtifactKey: output_train
                producerTask: load-data
          parameters:
            schema_file_path:
              runtimeValue:
                constant: /gcs/pistachio_pipeline_sbx_bucket/pipeline_resources/pistachio_schema.json
        taskInfo:
          name: validate training data
      validate-data-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-validate-data-2
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            input_file:
              taskOutputArtifact:
                outputArtifactKey: output_test
                producerTask: load-data
          parameters:
            schema_file_path:
              runtimeValue:
                constant: /gcs/pistachio_pipeline_sbx_bucket/pipeline_resources/pistachio_schema.json
        taskInfo:
          name: validate test data
  inputDefinitions:
    parameters:
      test_split_data_fraction:
        defaultValue: 0.2
        description: _description_
        isOptional: true
        parameterType: NUMBER_DOUBLE
      train_test_split_seed:
        defaultValue: 37.0
        description: _description_
        isOptional: true
        parameterType: NUMBER_INTEGER
      tuning_cv_seed:
        defaultValue: 73.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      tuning_opt_n_iter:
        defaultValue: 200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
  outputDefinitions:
    artifacts:
      evaluation-reporting-test_evaluation_metrics:
        artifactType:
          schemaTitle: system.ClassificationMetrics
          schemaVersion: 0.0.1
      evaluation-reporting-train_evaluation_metrics:
        artifactType:
          schemaTitle: system.ClassificationMetrics
          schemaVersion: 0.0.1
      psi-result-logging-psi_metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.3.0
